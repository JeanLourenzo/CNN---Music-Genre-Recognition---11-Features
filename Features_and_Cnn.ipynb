{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria o cabeçalho da lista CSV\n",
    "cab = 'filename zero_cr chroma_cqt chroma_cens tonnetz chroma_stf rmse spec_centroid spec_bandwidth spec_contrast spec_rolloff'\n",
    "for i in range(1, 21):\n",
    "    cab += f' mfcc{i}'\n",
    "cab += ' label'\n",
    "cab = cab.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um CSV, localiza todas pastas e arquivos no diretório, extrai as features das músicas,\n",
    "#concatena tudo dentro do CSV usando .append dentro do respetivo cabeçalho.\n",
    "file = open('D:/Final/Dados em CSV/data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(cab)\n",
    "\n",
    "generos = 'blues classical country disco hiphop jazz metal pop reggae rock'.split() #Divide.\n",
    "for g in generos: #Roda o for em todas pastas.\n",
    "  \n",
    "    for nome_arquivo in os.listdir(f'D:/Music Database/GTZAN Music Database/{g}'): #Roda arquivo por arquivo.\n",
    "     \n",
    "        musica = f'D:/Music Database/GTZAN Music Database/{g}/{nome_arquivo}'#Diretório da música.\n",
    "     \n",
    "        x, sr = librosa.load(musica, mono=True, duration=30) #Ler a música.\n",
    "      \n",
    "        #Extrai todas features abaixo, usando librosa.\n",
    "        zcr = librosa.feature.zero_crossing_rate(x, frame_length=2048, hop_length=512)\n",
    "      \n",
    "        cqt = np.abs(librosa.cqt(x, sr=sr, hop_length=512, bins_per_octave=12, n_bins=7*12, tuning=None))\n",
    "        assert cqt.shape[0] == 7 * 12\n",
    "        assert np.ceil(len(x)/512) <= cqt.shape[1] <= np.ceil(len(x)/512)+1\n",
    "      \n",
    "        chroma_cqt = librosa.feature.chroma_cqt(C=cqt, n_chroma=12, n_octaves=7)\n",
    "\n",
    "        chroma_cens = librosa.feature.chroma_cens(C=cqt, n_chroma=12, n_octaves=7)\n",
    "\n",
    "        tonnetz = librosa.feature.tonnetz(librosa.effects.harmonic(x), sr=sr)\n",
    "\n",
    "        del cqt\n",
    "        stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
    "        assert stft.shape[0] == 1 + 2048 // 2\n",
    "        assert np.ceil(len(x)/512) <= stft.shape[1] <= np.ceil(len(x)/512)+1\n",
    "        del x\n",
    "       \n",
    "        chroma_stft = librosa.feature.chroma_stft(S=stft**2, n_chroma=12)\n",
    "\n",
    "        rmse = librosa.feature.rmse(S=stft)\n",
    "\n",
    "        spec_cent = librosa.feature.spectral_centroid(S=stft)\n",
    "\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(S=stft)\n",
    "\n",
    "        spec_contrast = librosa.feature.spectral_contrast(S=stft, n_bands=6)\n",
    "\n",
    "        spec_rolloff = librosa.feature.spectral_rolloff(S=stft)\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
    "        del stft\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "\n",
    "        to_append = f'{nome_arquivo} {np.mean(zcr)} {np.mean(chroma_cqt)} {np.mean(chroma_cens)} {np.mean(tonnetz)} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(spec_contrast)} {np.mean(spec_rolloff)}'      \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('D:/Final/Dados em CSV/data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>zero_cr</th>\n",
       "      <th>chroma_cqt</th>\n",
       "      <th>chroma_cens</th>\n",
       "      <th>tonnetz</th>\n",
       "      <th>chroma_stf</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spec_centroid</th>\n",
       "      <th>spec_bandwidth</th>\n",
       "      <th>spec_contrast</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>0.549554</td>\n",
       "      <td>0.273436</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.349943</td>\n",
       "      <td>3.540670</td>\n",
       "      <td>1784.420446</td>\n",
       "      <td>2002.650192</td>\n",
       "      <td>20.530733</td>\n",
       "      <td>...</td>\n",
       "      <td>8.810668</td>\n",
       "      <td>-3.667367</td>\n",
       "      <td>5.751690</td>\n",
       "      <td>-5.162761</td>\n",
       "      <td>0.750947</td>\n",
       "      <td>-1.691937</td>\n",
       "      <td>-0.409954</td>\n",
       "      <td>-2.300208</td>\n",
       "      <td>1.219928</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>0.056044</td>\n",
       "      <td>0.503215</td>\n",
       "      <td>0.261366</td>\n",
       "      <td>0.018852</td>\n",
       "      <td>0.340983</td>\n",
       "      <td>2.601917</td>\n",
       "      <td>1529.835316</td>\n",
       "      <td>2038.617579</td>\n",
       "      <td>20.676334</td>\n",
       "      <td>...</td>\n",
       "      <td>5.376802</td>\n",
       "      <td>-2.239119</td>\n",
       "      <td>4.216963</td>\n",
       "      <td>-6.012273</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>-0.716537</td>\n",
       "      <td>0.293875</td>\n",
       "      <td>-0.287431</td>\n",
       "      <td>0.531573</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>0.076301</td>\n",
       "      <td>0.515355</td>\n",
       "      <td>0.267732</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.363603</td>\n",
       "      <td>4.798367</td>\n",
       "      <td>1552.481958</td>\n",
       "      <td>1747.165985</td>\n",
       "      <td>22.197265</td>\n",
       "      <td>...</td>\n",
       "      <td>5.789265</td>\n",
       "      <td>-8.905224</td>\n",
       "      <td>-1.083720</td>\n",
       "      <td>-9.218359</td>\n",
       "      <td>2.455805</td>\n",
       "      <td>-7.726901</td>\n",
       "      <td>-1.815724</td>\n",
       "      <td>-3.433434</td>\n",
       "      <td>-2.226821</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>0.033309</td>\n",
       "      <td>0.400808</td>\n",
       "      <td>0.238640</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>0.404779</td>\n",
       "      <td>3.852295</td>\n",
       "      <td>1070.119953</td>\n",
       "      <td>1596.333948</td>\n",
       "      <td>21.428764</td>\n",
       "      <td>...</td>\n",
       "      <td>6.087676</td>\n",
       "      <td>-2.476420</td>\n",
       "      <td>-1.073890</td>\n",
       "      <td>-2.874777</td>\n",
       "      <td>0.780976</td>\n",
       "      <td>-3.316932</td>\n",
       "      <td>0.637981</td>\n",
       "      <td>-0.619690</td>\n",
       "      <td>-3.408233</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>0.521289</td>\n",
       "      <td>0.266510</td>\n",
       "      <td>-0.050764</td>\n",
       "      <td>0.308590</td>\n",
       "      <td>2.487634</td>\n",
       "      <td>1835.494603</td>\n",
       "      <td>1748.362448</td>\n",
       "      <td>21.467739</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806385</td>\n",
       "      <td>-6.934122</td>\n",
       "      <td>-7.558619</td>\n",
       "      <td>-9.173552</td>\n",
       "      <td>-4.512166</td>\n",
       "      <td>-5.453538</td>\n",
       "      <td>-0.924162</td>\n",
       "      <td>-4.409333</td>\n",
       "      <td>-11.703781</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename   zero_cr  chroma_cqt  chroma_cens   tonnetz  chroma_stf  \\\n",
       "0  blues.00000.wav  0.083066    0.549554     0.273436  0.000684    0.349943   \n",
       "1  blues.00001.wav  0.056044    0.503215     0.261366  0.018852    0.340983   \n",
       "2  blues.00002.wav  0.076301    0.515355     0.267732  0.022247    0.363603   \n",
       "3  blues.00003.wav  0.033309    0.400808     0.238640  0.008652    0.404779   \n",
       "4  blues.00004.wav  0.101500    0.521289     0.266510 -0.050764    0.308590   \n",
       "\n",
       "       rmse  spec_centroid  spec_bandwidth  spec_contrast  ...    mfcc12  \\\n",
       "0  3.540670    1784.420446     2002.650192      20.530733  ...  8.810668   \n",
       "1  2.601917    1529.835316     2038.617579      20.676334  ...  5.376802   \n",
       "2  4.798367    1552.481958     1747.165985      22.197265  ...  5.789265   \n",
       "3  3.852295    1070.119953     1596.333948      21.428764  ...  6.087676   \n",
       "4  2.487634    1835.494603     1748.362448      21.467739  ... -2.806385   \n",
       "\n",
       "     mfcc13    mfcc14    mfcc15    mfcc16    mfcc17    mfcc18    mfcc19  \\\n",
       "0 -3.667367  5.751690 -5.162761  0.750947 -1.691937 -0.409954 -2.300208   \n",
       "1 -2.239119  4.216963 -6.012273  0.936109 -0.716537  0.293875 -0.287431   \n",
       "2 -8.905224 -1.083720 -9.218359  2.455805 -7.726901 -1.815724 -3.433434   \n",
       "3 -2.476420 -1.073890 -2.874777  0.780976 -3.316932  0.637981 -0.619690   \n",
       "4 -6.934122 -7.558619 -9.173552 -4.512166 -5.453538 -0.924162 -4.409333   \n",
       "\n",
       "      mfcc20  label  \n",
       "0   1.219928  blues  \n",
       "1   0.531573  blues  \n",
       "2  -2.226821  blues  \n",
       "3  -3.408233  blues  \n",
       "4 -11.703781  blues  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lê o arquivo CSV usando o pandas.\n",
    "todas_features = pd.read_csv('D:/Final/Dados em CSV/data.csv')\n",
    "todas_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclui a coluna com os nomes.\n",
    "todas_features = todas_features.drop(['filename'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma ligação entre os generos e um valor int, cada int representa um genero.\n",
    "genre_list = todas_features.iloc[:, -1] #Cria um int para cada label\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list) #Separa por labens distintas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X é calculado removendo o mean e divindo pela variancia.\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(todas_features.iloc[:, :-1], dtype = float))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 30) (200, 30) (800,) (200,)\n"
     ]
    }
   ],
   "source": [
    "#Dividi os dados entre treino e teste em 800/200.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,test_size=0.2, random_state=101)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Heaven\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Cria o modelo da CNN, com 256 neurônios.\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definições de como o modelo deverá ser treinado.\n",
    "model.compile(optimizer='adam', #Algoritimo Adam para otimizar a rede neural.\n",
    "              loss='sparse_categorical_crossentropy', #Função que utiliza as baixas.\n",
    "              metrics=['accuracy']) #Precisão escolhida como métrica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.0411 - acc: 0.9975\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.0396 - acc: 0.9975\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.0322 - acc: 0.9988\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.0331 - acc: 0.9962\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.0297 - acc: 0.9962\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.0262 - acc: 0.9988\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.0244 - acc: 0.9988\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.0227 - acc: 0.9975\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.0229 - acc: 0.9975\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.0193 - acc: 0.9975\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.0195 - acc: 0.9975\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.0201 - acc: 0.9975\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.0168 - acc: 0.9988\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.0167 - acc: 0.9988\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.0162 - acc: 0.9988\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.0152 - acc: 0.9988\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.0174 - acc: 0.9975\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.0130 - acc: 0.9975\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.0133 - acc: 0.9975\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.0125 - acc: 0.9975\n"
     ]
    }
   ],
   "source": [
    "#Treinando o modelo.\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 45us/step\n",
      "Precisão:  0.655\n",
      "Perdido:  1.9735085678100586\n"
     ]
    }
   ],
   "source": [
    "#Calculando a precisão e perca que o modelo conseguiu categorizando da musica baseado nas features extraidas.\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "print('Precisão: ', test_acc)\n",
    "print('Perdido: ', test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando 200 amostras para o teste de validação.\n",
    "x_val = X_train[:200]\n",
    "partial_x_train = X_train[200:]\n",
    "\n",
    "y_val = y_train[:200]\n",
    "partial_y_train = y_train[200:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria o modelo da CNN, com 512 neurônios.\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 200 samples\n",
      "Epoch 1/30\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.2601 - acc: 0.1950 - val_loss: 2.0842 - val_acc: 0.2700\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 0s 57us/step - loss: 2.0102 - acc: 0.2850 - val_loss: 1.8770 - val_acc: 0.2950\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 0s 53us/step - loss: 1.7925 - acc: 0.3067 - val_loss: 1.6971 - val_acc: 0.3600\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 0s 53us/step - loss: 1.6037 - acc: 0.4050 - val_loss: 1.5417 - val_acc: 0.5000\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 0s 52us/step - loss: 1.4481 - acc: 0.5167 - val_loss: 1.3928 - val_acc: 0.5200\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 0s 52us/step - loss: 1.3138 - acc: 0.5383 - val_loss: 1.3268 - val_acc: 0.5550\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 0s 50us/step - loss: 1.1805 - acc: 0.6250 - val_loss: 1.2403 - val_acc: 0.5750\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 0s 55us/step - loss: 1.0545 - acc: 0.6650 - val_loss: 1.1751 - val_acc: 0.5600\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.9596 - acc: 0.7033 - val_loss: 1.1421 - val_acc: 0.5850\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.8711 - acc: 0.7333 - val_loss: 1.0618 - val_acc: 0.6200\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.7917 - acc: 0.7650 - val_loss: 1.0582 - val_acc: 0.6350\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.7303 - acc: 0.7900 - val_loss: 1.0202 - val_acc: 0.6350\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.6679 - acc: 0.7983 - val_loss: 1.0152 - val_acc: 0.6400\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 0s 73us/step - loss: 0.6216 - acc: 0.8083 - val_loss: 0.9541 - val_acc: 0.6850\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.5481 - acc: 0.8500 - val_loss: 0.9451 - val_acc: 0.6700\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.5226 - acc: 0.8533 - val_loss: 0.9179 - val_acc: 0.7000\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4602 - acc: 0.8783 - val_loss: 0.9339 - val_acc: 0.6900\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.4265 - acc: 0.8900 - val_loss: 0.9239 - val_acc: 0.6700\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.4098 - acc: 0.8900 - val_loss: 0.8979 - val_acc: 0.6850\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.3510 - acc: 0.9217 - val_loss: 0.9680 - val_acc: 0.6900\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.3377 - acc: 0.9200 - val_loss: 0.8866 - val_acc: 0.6900\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.2949 - acc: 0.9400 - val_loss: 0.9587 - val_acc: 0.6900\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.2793 - acc: 0.9283 - val_loss: 0.9484 - val_acc: 0.6600\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.2476 - acc: 0.9450 - val_loss: 0.9049 - val_acc: 0.6850\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.2266 - acc: 0.9550 - val_loss: 0.9277 - val_acc: 0.6850\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.2131 - acc: 0.9617 - val_loss: 0.9046 - val_acc: 0.7050\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.1879 - acc: 0.9667 - val_loss: 0.9743 - val_acc: 0.6800\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1710 - acc: 0.9700 - val_loss: 0.9161 - val_acc: 0.7050\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.1550 - acc: 0.9800 - val_loss: 0.9659 - val_acc: 0.6850\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.1377 - acc: 0.9817 - val_loss: 0.9654 - val_acc: 0.6750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7da05ba90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definições de como o modelo deverá ser treinado.\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Treinando o modelo.\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=30,\n",
    "          batch_size=256,\n",
    "          validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 324us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3783106994628906, 0.67]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = model.evaluate(X_test, y_test)\n",
    "resultado\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
